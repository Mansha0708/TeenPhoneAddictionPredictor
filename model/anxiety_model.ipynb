{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d7c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"train_anxiety_model.ipynb\n",
    "\n",
    "This notebook preprocesses the teen phone addiction dataset,\n",
    "engineers features, and then trains an XGBoost Regressor model\n",
    "to predict 'Anxiety_Level'. The trained model is saved as 'anxiety_model.pkl'.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import RandomForestRegressor # Removed\n",
    "from xgboost import XGBRegressor # Added XGBoost\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# --- Configuration ---\n",
    "# Adjust this path based on where your notebook is relative to the CSV file.\n",
    "# Assuming this notebook is in 'teenaddiction/model/' and CSV is in 'teenaddiction/data/'\n",
    "DATASET_PATH = '../data/teen_phone_addiction_dataset.csv'\n",
    "MODEL_OUTPUT_PATH = 'anxiety_model.pkl' # Model will be saved in the same directory as this notebook\n",
    "\n",
    "# --- 2. Load your dataset ---\n",
    "try:\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(f\"Initial shape: {df.shape}\")\n",
    "    print(\"Initial columns:\", df.columns.tolist())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Dataset not found at {DATASET_PATH}.\")\n",
    "    print(\"Please ensure 'teen_phone_addiction_dataset.csv' is in the 'data/' directory.\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Data Cleaning and Preprocessing (Consistent with main training) ---\n",
    "\n",
    "# Define columns to drop (identifiers and potentially redundant/leaky target-related columns)\n",
    "# Note: 'Anxiety_Level' is the target here, so it's not dropped initially.\n",
    "# 'Depression_Level' and 'Addiction_Level' are features for this model.\n",
    "columns_to_drop_initial = [\"ID\", \"Name\", \"Location\", \"Depression_Class\", \"Depression_Level_Class\", \"Anxiety_Class\", \"Usage_Bin\", \"Usage_Group\"]\n",
    "existing_columns_to_drop = [col for col in columns_to_drop_initial if col in df.columns]\n",
    "\n",
    "if existing_columns_to_drop:\n",
    "    df.drop(columns=existing_columns_to_drop, inplace=True)\n",
    "    print(f\"\\nDropped columns: {existing_columns_to_drop}\")\n",
    "else:\n",
    "    print(\"\\nNo specified initial columns to drop were found in the DataFrame (or already dropped).\")\n",
    "\n",
    "# Handle missing values (dropping rows for simplicity)\n",
    "print(\"\\nMissing values before dropping NaNs:\\n\", df.isnull().sum())\n",
    "df.dropna(inplace=True)\n",
    "print(\"\\nMissing values after dropping NaNs:\\n\", df.isnull().sum())\n",
    "\n",
    "# Encode categorical columns using One-Hot Encoding\n",
    "categorical_cols_to_encode = ['Gender', 'School_Grade', 'Phone_Usage_Purpose']\n",
    "existing_categorical_cols = [col for col in categorical_cols_to_encode if col in df.columns]\n",
    "\n",
    "if existing_categorical_cols:\n",
    "    df = pd.get_dummies(df, columns=existing_categorical_cols, drop_first=True)\n",
    "    print(f\"\\nOne-hot encoded columns: {existing_categorical_cols}\")\n",
    "else:\n",
    "    print(\"\\nNo specified categorical columns to encode were found.\")\n",
    "\n",
    "# --- 4. Feature Engineering (Consistent with main training) ---\n",
    "required_base_cols = [\n",
    "    'Daily_Usage_Hours', 'Screen_Time_Before_Bed', 'Time_on_Social_Media',\n",
    "    'Time_on_Education', 'Time_on_Gaming', 'Weekend_Usage_Hours',\n",
    "    'Phone_Checks_Per_Day', 'Apps_Used_Daily', 'Sleep_Hours'\n",
    "]\n",
    "\n",
    "if all(col in df.columns for col in required_base_cols):\n",
    "    df['Night_Usage'] = df['Daily_Usage_Hours'] - df['Screen_Time_Before_Bed']\n",
    "    df['Social_to_Edu_Ratio'] = (df['Time_on_Social_Media'] + 1) / (df['Time_on_Education'] + 1)\n",
    "    df['Gaming_to_Social_Ratio'] = (df['Time_on_Gaming'] + 1) / (df['Time_on_Social_Media'] + 1)\n",
    "    df['Weekend_Overuse'] = df['Weekend_Usage_Hours'] - df['Daily_Usage_Hours']\n",
    "    df['Phone_Obsessiveness'] = df['Phone_Checks_Per_Day'] / (df['Apps_Used_Daily'] + 1)\n",
    "    df['Sleep_Deficit'] = 8 - df['Sleep_Hours']\n",
    "    print(\"\\nEngineered new features.\")\n",
    "else:\n",
    "    print(\"\\nWarning: Some base columns for feature engineering are missing. Skipping feature engineering.\")\n",
    "\n",
    "# --- 5. Define features (X) and target (y) for Anxiety Model ---\n",
    "# X includes all features EXCEPT Addiction_Level, and Depression_Level (as these are not direct inputs for Anxiety prediction)\n",
    "# The order of these features MUST match 'features_for_sub_models' in your Streamlit app.\n",
    "features_for_anxiety_model = [\n",
    "    'Age', 'Daily_Usage_Hours', 'Sleep_Hours', 'Academic_Performance',\n",
    "    'Social_Interactions', 'Exercise_Hours', 'Self_Esteem', 'Parental_Control',\n",
    "    'Screen_Time_Before_Bed', 'Phone_Checks_Per_Day', 'Apps_Used_Daily',\n",
    "    'Time_on_Social_Media', 'Time_on_Gaming', 'Time_on_Education',\n",
    "    'Family_Communication', 'Weekend_Usage_Hours',\n",
    "    'Gender_Male', 'Gender_Other',\n",
    "    'School_Grade_11th', 'School_Grade_12th', 'School_Grade_7th',\n",
    "    'School_Grade_8th', 'School_Grade_9th',\n",
    "    'Phone_Usage_Purpose_Education', 'Phone_Usage_Purpose_Gaming',\n",
    "    'Phone_Usage_Purpose_Other', 'Phone_Usage_Purpose_Social Media',\n",
    "    'Night_Usage', 'Social_to_Edu_Ratio', 'Gaming_to_Social_Ratio',\n",
    "    'Weekend_Overuse', 'Phone_Obsessiveness', 'Sleep_Deficit'\n",
    "]\n",
    "\n",
    "if 'Anxiety_Level' in df.columns and all(col in df.columns for col in features_for_anxiety_model):\n",
    "    X_anxiety = df[features_for_anxiety_model]\n",
    "    y_anxiety = df['Anxiety_Level']\n",
    "    print(f\"\\nFeatures (X_anxiety) shape: {X_anxiety.shape}\")\n",
    "    print(f\"Target (y_anxiety) shape: {y_anxiety.shape}\")\n",
    "    print(\"\\nFeatures used for Anxiety model training (X_anxiety.columns.tolist()):\")\n",
    "    print(X_anxiety.columns.tolist()) # CRITICAL: Verify this list matches Streamlit app's 'features_for_sub_models'\n",
    "else:\n",
    "    print(\"Error: Required columns for Anxiety model not found in DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# --- 6. Train/test split ---\n",
    "X_train_anx, X_test_anx, y_train_anx, y_test_anx = train_test_split(X_anxiety, y_anxiety, test_size=0.2, random_state=42)\n",
    "print(f\"\\nTraining data shape: {X_train_anx.shape}, Test data shape: {X_test_anx.shape}\")\n",
    "\n",
    "# --- 7. Train model ---\n",
    "print(\"\\nTraining XGBoost Regressor for Anxiety_Level...\")\n",
    "# Changed to XGBRegressor\n",
    "anxiety_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "anxiety_model.fit(X_train_anx, y_train_anx)\n",
    "print(\"Anxiety model training complete.\")\n",
    "\n",
    "# --- 8. Evaluate model ---\n",
    "preds_anx = anxiety_model.predict(X_test_anx)\n",
    "\n",
    "r2_anx = r2_score(y_test_anx, preds_anx)\n",
    "print(f\"\\nAnxiety Model Evaluation:\")\n",
    "\n",
    "print(f\"  R-squared: {r2_anx:.2f}\")\n",
    "\n",
    "# --- 9. Save model ---\n",
    "joblib.dump(anxiety_model, MODEL_OUTPUT_PATH)\n",
    "print(f\"\\nâœ… Anxiety model saved as '{MODEL_OUTPUT_PATH}'\")\n",
    "\n",
    "print(\"\\n--- Anxiety Model Training Script Finished ---\")\n",
    "print(\"Next steps:\")\n",
    "print(f\"1. The '{MODEL_OUTPUT_PATH}' file is now saved in your 'teenaddiction/model/' directory.\")\n",
    "print(\"2. Ensure this model is placed in the 'model/' directory of your Streamlit app.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
